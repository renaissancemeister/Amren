<!DOCTYPE html>
<html lang="en-US">
<head>
<!-- #bbinclude "meta.incl" -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="content-language" content="en-US">
<!-- Bootstrap -->
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous">
<!-- our CSS -->
	<link rel="stylesheet" type="text/css" href="/_assets/css/screen.css" media="screen">
<!--load jquery -->
	<script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
	<meta name="author" content="New Century Foundation copyright 1990-2020">
	<meta name="keywords" content="Amren, American Renaissance, race realism, racialism, race relations">
<!-- end bbinclude -->
	<title>Are Face-Detection Cameras Racist?</title>
</head>
<body>
<!-- #bbinclude "header.incl" -->
<header class="container-fluid">
	<div class="row">
		<div class="col-md-12">
			<a href="/index.html"><img src="/_assets/graphics/AR-masthead.jpg" alt="American Renaissance" width="724" height="75" class="img-responsive masthead"></a>
		</div>
	</div>
</header>
<!-- end bbinclude -->
<!-- #bbinclude "nav.incl" -->
<div id="navbar-bg"></div>
<script>
$(document).ready(function () {
  $("#navbar-bg").html("Loading ...").load("/_assets/includes/topnav.htm");
});
</script>
<div class="container" id="content">
	<div class="row">
		<div class="col-md-12">
<!-- end bbinclude -->
<!-- start of the live area for this page -->
<h1><a href="https://www.time.com/time/business/article/0,8599,1954643,00.html">Are Face-Detection Cameras Racist?</a></h1>

			<p style="font-size: smaller"><i>Adam Rose, Time, January 22, 2010</i></p>
<!-- This is the full text of the entry -->
	<p>When Joz Wang and her brother bought their mom a Nikon Coolpix S630 digital camera for Mother&rsquo;s Day last year, they discovered what seemed to be a malfunction. Every time they took a portrait of each other smiling, a message flashed across the screen asking, &#8220;Did someone blink?&#8221; No one had. &#8220;I thought the camera was broken!&#8221; Wang, 33, recalls. But when her brother posed with his eyes open so wide that he looked &#8220;bug-eyed,&#8221; the messages stopped.</p>
<p>Wang, a Taiwanese-American strategy consultant who goes by the Web handle &#8220;jozjozjoz,&#8221; thought it was funny that the camera had difficulties figuring out when her family had their eyes open. So she posted a photo of the blink warning on her blog under the title, &#8220;Racist Camera! No, I did not blink.&nbsp;.&nbsp;.&nbsp;. I&rsquo;m just Asian!&#8221; {snip}</p>
<p>Nikon isn&rsquo;t the only big brand whose consumer cameras have displayed an occasional  &mdash;  though clearly unintentional  &mdash;  bias toward Caucasian faces. Face detection, which is one of the latest &#8220;intelligent&#8221; technologies to trickle down to consumer cameras, is supposed to make photography more convenient. Some cameras with face detection are designed to warn you when someone blinks; others are programmed to automatically take a picture when somebody smiles  &mdash;  a feature that, theoretically, makes the whole problem of timing your shot to catch the brief glimpse of a grin obsolete. Face detection has also found its way into computer webcams, where it can track a person&rsquo;s face during a video conference or enable face-recognition software to prevent unauthorized access.</p>
<p>{snip}</p>
<p>Indeed, just last month, a white employee at an RV dealership in Texas posted a YouTube video showing a black co-worker trying to get the built-in webcam on an HP Pavilion laptop to detect his face and track his movements. The camera zoomed in on the white employee and panned to follow her, but whenever the black employee came into the frame, the webcam stopped dead in its tracks. &#8220;I think my blackness is interfering with the computer&rsquo;s ability to follow me,&#8221; the black employee jokingly concludes in the video. &#8220;Hewlett-Packard computers are racist.&#8221;</p>
<p>{snip}</p>
<p>{snip} TIME tested two of Sony&rsquo;s latest Cyber-shot models with face detection (the DSC-TX1 and DSC-WX1) and found they, too, had a tendency to ignore camera subjects with dark complexions.</p>
<p>But why? It&rsquo;s not necessarily the programmers&rsquo; fault. It comes down to the fact that the software is only as good as its algorithms, or the mathematical rules used to determine what a face is. There are two ways to create them: by hard-coding a list of rules for the computer to follow when looking for a face, or by showing it a sample set of hundreds, if not thousands, of images and letting it figure out what the ones with faces have in common. In this way, a computer can create its own list of rules, and then programmers will tweak them. You might think the more images  &mdash;  and the more diverse the images  &mdash;  that a computer is fed, the better the system will get, but sometimes the opposite is true. The images can begin to generate rules that contradict each other. &#8220;If you have a set of 95 images and it recognizes 90 of those, and you feed it five more, you might gain five, but lose three,&#8221; says Vincent Hubert, a software engineer at Montreal-based Simbioz, a tech company that is developing futuristic hand-gesture technology like the kind seen in Minority Report. It&rsquo;s the same kind of problem speech-recognition software faces in handling unusual accents.</p>
<p>And just as the software is only as good as its code and the hardware it lives in, it&rsquo;s also only as good as the light it&rsquo;s got to work with. {snip} That&rsquo;s one reason why a person watching the YouTube video can easily make out the black employee&rsquo;s face, while the computer can&rsquo;t. &#8220;A racially inclusive training set won&rsquo;t help if the larger platform is not capable of seeing those details,&#8221; says Steve Russell, founder and chairman of 3VR, which creates face recognition for security cameras.</p>
<p>The blink problem Wang complained about has less to do with lighting than the plain fact that her Nikon was incapable of distinguishing her narrow eye from a half-closed one. An eye might only be a few pixels wide, and a camera that&rsquo;s downsampling the images can&rsquo;t see the necessary level of detail. So a trade-off has to be made: either the blink warning would have a tendency to miss half blinks or a tendency to trigger for narrow eyes. {snip}</p>
<p>{snip}<br>
</p>
<!-- This is the URL of the original article, if available -->
							<p>
								 <a href="https://www.time.com/time/business/article/0,8599,1954643,00.html"><b>Original article</b></a></font> 
							</p>
<!-- name and e-mail of the original author -->
				<p>
					(Posted on January 22, 2010) </font>
				</p>
<!-- This is a related article, if entered -->
<!-- Here are the image and caption to accompany the article, if entered -->
<!-- navigation section -->
				<div class="text-center">
					<font size="1"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="/">Previous story</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="/news/2010/01/census_figures.html">Next Story</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
				<a href="#post">Post a Comment</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="/search.html">Search</a></font> 
		</div>
<hr>
	<a id="comments"></a>
	<h2>Comments</h2> 
<a id="c629621"></a>
<fieldset>
		<legend class="commenter">
			1  &mdash;  <a href="mailto:hfmorton@yahoo.com">Howard</a> wrote at  7:01 PM on <a href="#c629621">January 22</a>:
		</legend>
		<p>These cameras are made in China like all other pieces of electronic equipment so are the Chinese racist against Asians?</p>
</fieldset>
<a id="c629632"></a>
<fieldset>
		<legend class="commenter">
			2  &mdash;  Jon wrote at  7:46 PM on <a href="#c629632">January 22</a>:
		</legend>
		<p>Nikon is a Japanese company, so I highly doubt they&rsquo;re intentionally persecuting East Asians.</p>
<p>I&rsquo;d imagine if the tracking cameras were being used in a security application the blacks&rsquo; complaints would be completely the opposite. It&rsquo;d probably be &#8220;racist&#8221; if the cameras did track their faces!</p>
</fieldset>
<a id="c629700"></a>
<fieldset>
		<legend class="commenter">
			3  &mdash;  Anonymous wrote at  1:38 AM on <a href="#c629700">January 23</a>:
		</legend>
		<p>The real question is: is face-detection technology flawed? Looking at this article it seems to be. Calling a camera racist is just stupid beyond comprehension. </p>
</fieldset>
<a id="c629779"></a>
<fieldset>
		<legend class="commenter">
			4  &mdash;  Anonymous wrote at 11:43 AM on <a href="#c629779">January 23</a>:
		</legend>
		<p>Another way to look at this is that the technology can track white people very well.<br>
White people commit less crime.  It cannot track black people at all.  Black people who do most of the crime, and against whom the technology could be useful being used to track the black thug who just murdered the mini-mart staff and ran.  It also illustrates the black IQ level.  The black who is complaining about the cameras and technology being racist is too stupid to realize that flaw benefits his kind.</p>
</fieldset>
<a id="c629783"></a>
<fieldset>
		<legend class="commenter">
			5  &mdash;  Istvan wrote at 11:57 AM on <a href="#c629783">January 23</a>:
		</legend>
		<p>Don&rsquo;t Japanese people have &#8220;bigger&#8221; eyes than Chinese?  If that is the case the developers probably tested their program on their two largest markets: Japan and the US.  They may not have thought about the physical differences between them and the Chinese.  But racist?  Oh my, everything is racist these days and is a statement with little relationship to reality, except of course to money-hungry &#8220;civil rights&#8221; lawyers and left-wing judges.</p>
</fieldset>
<a id="c629809"></a>
<fieldset>
		<legend class="commenter">
			6  &mdash;  Jeddermann wrote at  3:45 PM on <a href="#c629809">January 23</a>:
		</legend>
		<p>&#8220;It comes down to the fact that the software is only as good as its algorithms, or the mathematical rules used to determine what a face is&#8221;</p>
<p>This is exactly the case. The algorithm was written and tested on a certain specific group and NO ONE gave a thought it would not work on &#8220;others&#8221;. The thought did not ever ENTER the mind of anyone to check out the operation of the camera on &#8220;others&#8221;. NO offense intended.</p>
</fieldset>
<a id="c629821"></a>
<fieldset>
		<legend class="commenter">
			7  &mdash;  John wrote at  4:23 PM on <a href="#c629821">January 23</a>:
		</legend>
		<p>C&rsquo;mon, guys, lighten up a bit.</p>
<p>This is just a rather amusing story of some photographic software limitations that have problems with certain racial characteristics, such as narrower Asian eyes or black skin tones. </p>
<p>I didn&rsquo;t see anybody in the article yowling about racist programming or starting Civil Rights Act actions.</p>
</fieldset>
<a id="c630214"></a>
<fieldset>
		<legend class="commenter">
			8  &mdash;  Anonymous wrote at 11:28 PM on <a href="#c630214">January 25</a>:
		</legend>
		<p>Are Face-Detection Cameras Racist? No!</p>
<p>Is Time magazine a serious source for news and commentary? No!</p>
</fieldset>
<br>
<div class="text-center">
						<font size="1"><a href="/">Home</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#top">Top</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="/">Previous story</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
						<a href="/news/2010/01/census_figures.html">Next Story</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
					 <a href="/search.html">Search</a></font> 
</div>
<a id="post"></a>
<h2>Post a Comment</h2> 
			<table width="400" align="center" cellspacing="5" cellpadding="10">
				<tr>
					<td height="90">
						<div>
							<p><strong>Commenting guidelines:</strong></p>
							<p>We welcome comments that add information or perspective, and we encourage polite debate. Statements of fact and well-considered opinion are welcome, but we will not post comments that include <a href="/guidelines.html">obscenities or insults</a>, whether of groups or individuals. We reserve the right to hold our critics to lower standards.</p>
							<p>If you agree with the guidelines above and you would like to comment, <a href="#" class="button" id="toggle"><span>click here</span></a>.</p> 
						</div>
					</td>
				</tr>
			</table>
<div id="v-form" class="v-form">
	<form method="post" action="/cgi-bin/mt/mt-comments.cgi" name="comments_form" onsubmit="if (this.bakecookie[0].checked) rememberMe(this)">
		<input type="hidden" name="static" value="1"> <input type="hidden" name="entry_id" value="18642"> 
		<div id="name_email">
			<p>
				<label for="author">Name (optional):</label> 
				<br>
				<input tabindex="1" id="author" name="author"> 
			</p>
			<p>
				<label for="email">Email Address (optional):</label> 
				<br>
				<input tabindex="2" id="email" name="email">
<script language="javascript" type="text/javascript">
<!--
if (commenter_name) {
    document.getElementById('name_email').style.display = 'none';
}
//-->
</script> 
				<br>
					Remember Me? <input type="radio" id="remember" onclick="rememberMe(this.form)" name="bakecookie"> <label for="remember">Yes</label> <input type="radio" id="forget" name="bakecookie" onclick="forgetMe(this.form)" value="Forget Info" style="margin-left: 15px;"> <label for="forget">No</label> 
			<br style="clear: both;">
	</p>
</div>
<p>
	<label for="text">Comments</label> 
		(you may use HTML tags for style) 
	<br>
<textarea tabindex="4" id="text" name="text" rows="10" cols="65"></textarea> 
</p>
<div class="text-center">
	<input style="font-weight: bold;" type="submit" name="post" tabindex="6" value=" Post "> 
</div>
</form>
<p>Note: If you are including long URLs in your comments, please first tokenize them using <a href="https://www.tinyurl.com/">TinyURL.com</a>.</p>
<p>&nbsp;</p>
</div>
<p>&nbsp;</p>
<script type="text/javascript" language="javascript">
<!--
if (document.comments_form.email != undefined)
    document.comments_form.email.value = getCookie("mtcmtmail");
if (document.comments_form.author != undefined)
    document.comments_form.author.value = getCookie("mtcmtauth");
if (document.comments_form.url != undefined)
    document.comments_form.url.value = getCookie("mtcmthome");
if (getCookie("mtcmtauth") || getCookie("mtcmthome")) {
    document.comments_form.bakecookie[0].checked = true;
} else {
    document.comments_form.bakecookie[1].checked = true;
}
//-->
</script>
<!-- end of the live area for this page -->
<!-- #bbinclude "footer.incl" -->
		</div><!-- .col-md-12 -->
	</div><!-- .row -->
</div><!-- .container-fluid -->
	<div class="row">
		<div class="col-md-12">
			<div class="footer">
				<hr>
				<p class="small text-center">
					The contents of this reconstructed website archive are copyright &copy; 1990-2020 <a href="https://www.amren.com/">New Century Foundation</a>. All Rights Reserved.
				</p>
			</div>
		</div><!-- .col-md-12 -->
	</div><!-- .row -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>
<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
<!-- end bbinclude -->
</body>

</html>
